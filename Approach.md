````markdown
# Firewall Threat & Anomaly Detection â€“ Project Overview

## 1. Why weâ€™re doing this
Firewalls throw off millions of log lines every single day. No human has time to read them all.  
Our mission is to let data science do the heavy lifting:

* **Explore the raw logs** to spot patterns and painâ€‘points.  
* **Detect threats and anomalies automatically** in (almost) real time.  
* **Show the results in a simple dashboard** so analysts can focus on what matters.

---

## 2. The data we use
* **Source:** [Internet Firewall Data Set (Kaggle)](https://www.kaggle.com/datasets/tunguz/internet-firewall-data-set)  
* **Where it lives in this repo:** `data/combined_firewall.csv` (plus raw/intermediate files)  
* **Extra features:** `data_synthesis.py` adds things like `total_traffic_bytes` and `hour_of_day`.

| Column | Meaning |
|--------|---------|
| `timestamp` | UTC time of the log entry |
| `src_ip`, `dst_ip` | source / destination address |
| `bytes_sent`, `bytes_received` | traffic volume |
| `application`, `url_category` | higherâ€‘level context |
| `action` | what the firewall did (allow / deny / drop) |

---

## 3. What we found in the data
See **`01_data_eda.ipynb`** for the full walkthrough, but in short:

* A handful of IPs hog most of the bandwidth (rightâ€‘skewed traffic).  
* Over 80â€¯% of denied or dropped packets come from fewer than 5â€¯% of source IPs â€“ prime blockâ€‘list material.  
* Traffic follows the 8â€¯AMâ€“6â€¯PM workday; spikes outside those hours are suspicious.  
* â€œUnknownâ€ or â€œSuspiciousâ€ URL categories are denied/dropped more than six times the global rate.

---

## 4. Features we feed the model
First pass, we keep it simple:

1. `bytes_sent`  
2. `bytes_received`  
3. `total_traffic_bytes` (sentâ€¯+â€¯received)  
4. `hour_of_day` (from the timestamp)

Everything is scaled with `StandardScaler` and saved to `scaler.joblib`.

---

## 5. How the model works
Because the logs arenâ€™t labelled, we lean on **unsupervised learning**.

* **Algorithm:** Isolation Forest (via `pyod`)  
* **Assumed threat rate (contamination):** 2â€¯%  
* **Notebook:** **`02_model.ipynb`**

### Quickâ€‘andâ€‘dirty evaluation
We treat `action` âˆˆâ€¯{deny, drop} as â€œprobably badâ€ and the rest as â€œprobably fineâ€:

| Metric | Score |
|--------|-------|
| Precision | **0.15** |
| Recall | **1.00** |
| F1 | **0.26** |

High recall means we catch (almost) everything, even if we flag too many false positives for now. Future work will raise precision with richer features.

The trained model lives in `model.joblib`.

---

## 6. The dashboard
File: **`dashboard.py`** (Streamlit)

What you can do with it:

* Filter by time (all time, last hour, 12â€¯h, 24â€¯h)  
* See pie charts for applications, URL categories, source and destination IPs  
* View a barâ€‘chart timeâ€‘series of total traffic  
* Scan tables of top users and categories  
* Compare allow vs deny/drop actions

Run it with:
```bash
streamlit run dashboard.py
````

### ğŸ“· Dashboard screenshot

*(Replace the image below with your own)*

```html
<!-- DASHBOARD_IMAGE_PLACEHOLDER -->
<img src="path/to/your/dashboard_screenshot.png" alt="Dashboard preview" width="100%">
```

---

## 7. Reâ€‘creating everything on your machine

### 7.1 Set up the environment

```bash
python -m venv env
source env/bin/activate      # Windows: env\Scripts\activate
pip install -r requirements.txt
# Add 'fpdf' if you want PDF export from the dashboard
```

### 7.2 Prepare the data

Combine and enrich the raw Kaggle CSVs:

```bash
python prepare_enriched_data.py   # or run the notebook cells
```

### 7.3 (Re)train the model â€“ optional

```bash
jupyter notebook 02_model.ipynb   # run all cells
```

### 7.4 Launch the dashboard

```bash
streamlit run dashboard.py
```

---

## 8. Repo at a glance

```
â”‚  Approach.md            â† (this file)
â”‚  requirements.txt       â† dependencies
â”‚  dashboard.py           â† Streamlit app
â”‚  prepare_enriched_data.py
â”‚  data_synthesis.py
â”‚  model.joblib, scaler.joblib
â”‚  01_data_eda.ipynb
â”‚  02_model.ipynb
â””â”€ data/
   â””â”€ combined_firewall.csv
```

---

## 9. Where weâ€™re heading next

* Bring in categorical features (oneâ€‘hot or embeddings).
* Expose the model as a realâ€‘time REST service (FastAPI).
* Add Slack/email alerts when an anomaly score pops above a threshold.
* Try other algorithms (AutoEncoder, Oneâ€‘Class SVM) and maybe ensemble them.

---

Â©â€¯2025 â€“ Firewall Threat Detection Project

```
```
